{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "A partir de un dataset generado a partir de la extracción de características (features) de la base de datos de sonidos de [RedPanal](https://redpanal.org), un sitio colaborativo que almacena y reproduce a demanda sonidos compartidos con licencias del tipo [Creative Commons](https://creativecommons.org/), se busca extraer conocimiento sobre la composición de la base de datos utilizando diferentes algoritmos de Machine Learning.\n",
    "\n",
    "Para extraer features de los archivos de sonido se utilizo el [Audio Commons Extractor](https://github.com/AudioCommons/ac-audio-extractor) que genera para cada sonido un archivo JSON con diferentes valores como: duración, tonalidad, rango dinámico, volumen, si es el sonido es \"loopeable o no\", si se trata de un \"evento único\" o no, entre otros.\n",
    "\n",
    "Originalmente la idea era analizar aquellos cuya duración era menor a 5 segundos, ya que a priori se pensaba que de los mismos se podía extraer mejor información, ya que su contenido no varia tanto en el tiempo, pero se descartó, ya que se encontró que el dataset elegido contaba con muy pocas instancias de este tipo.\n",
    "\n",
    "## Dependencias\n",
    "\n",
    "Consultar [Dependencias.md](Dependencias.md)\n",
    "\n",
    "\n",
    "# Armar Dataset\n",
    "\n",
    "Se utilizan los archivos .py especialmente programados para esta tarea.\n",
    "\n",
    "### Paso 1: Convertir archivos a .wav\n",
    "\n",
    "Convertir todos los archivos de audio a un mismo formato estándar como WAV 16bits y 44.1kHz\n",
    "\n",
    "Sintaxis: ./1_convert_all_files_to_wav.py [FILES_DIR] [WAVS_DIR]\n",
    "\n",
    "### Paso 2: Calcular features/descriptores MIR\n",
    "\n",
    "Sintaxis: ./2_files_mir_analysis.py [FILES_DIR] [JSON_DIR]\n",
    "\n",
    "Este paso hace uso del [Audio Commons Extractor](https://github.com/AudioCommons/ac-audio-extractor) mencionado, utilizando el contenedor Docker y se configura para utilizar generar por cada archivo de audio un .json plano o con la ontología para descripción de audio propuesta por el artículo: https://www.audiocommons.org/2018/07/15/audio-commons-audio-extractor.html.\n",
    "\n",
    "### (opcional) Paso 3: Separa canciones de 'muestras' según duración\n",
    "\n",
    "Este paso se aplica solo para algunos análisis y separa sonidos de menos de 5 segundos de duración en diferentes directorios.\n",
    " \n",
    "Sintaxis: ./3_separate_samples_and_songs.py ./json\n",
    "\n",
    "### Paso 4: Convertir los archivos JSON en un único archivo separado por comas (.csv)\n",
    "\n",
    "Genera un único archivo .csv compatible con python sklearn o R según configuración.\n",
    "\n",
    "Sintaxis: ./4_json_files_to_csv.py json-songs/\n",
    "\n",
    "Se calcula la cantidad de líneas generadas:\n",
    "\n",
    "    cat snd-dataset-from-plain-json.csv | wc -l\n",
    "    1018\n",
    "\n",
    "Por lo cual se observa que el dataset se compone de 1017 instancias (se resta una unidad porque la primera línea define los nombres de las columnas).\n",
    "\n",
    "---\n",
    "\n",
    "**Siguente:** [1 - Visualización y clustering](1%20-%20Visualización%20y%20clustering.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
